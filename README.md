# **Unsupervised Video Generation from Static Images**
ğŸ”¹ **Generating realistic videos from static images using stable video diffusion models.**  

<p align="center">
  <span style="float: left;"><b>Image Input = </b></span>
  <span style="float: right;"><b>Video Output</b></span>
  <br><br>
  <img src="asset/One.png" width="400"/>
  <img src="asset/image generation.gif" width="400"/>
</p>



---

## ğŸ“ **Overview**
This project explores **unsupervised video generation** from static images using **Stable Video Diffusion (SVD)** models. The model evaluates **temporal consistency, sharpness, brightness, noise levels**, and **overall video quality**.  

ğŸ“Œ **Key Contributions:**  
âœ… **Stable video diffusion** for high-quality video synthesis  
âœ… **Comparison of Colab (GPU) & OpenVINO (CPU) performance**  
âœ… **Temporal consistency and sharpness evaluation**  
âœ… **Optimization techniques for resource-efficient deployment**  

---

## ğŸ” **Motivation**
Generating **realistic video from a single image** has applications in:
- ğŸ® **Gaming & Animation** (AI-generated cinematic sequences)  
- ğŸ¥ **Medical Imaging** (3D reconstruction from 2D images)  
- ğŸ¥ **Content Creation & Simulation** (Synthetic video generation)  
- ğŸ•¶ **Augmented & Virtual Reality (AR/VR)**  

However, deploying such models across **GPU-heavy** and **CPU-limited platforms** is a challenge. This study aims to **evaluate performance trade-offs** for **high-quality and resource-efficient video generation**.

---

## **ğŸ› ï¸ Methodology**
This project employs **Stable Video Diffusion (SVD)** for **image-to-video generation**, leveraging **deep learning architectures** to create **coherent motion across frames**.

### **ğŸ“Œ System Architecture**
<p align="center">
  <img src="asset/SVD.png" width="700px">
</p>

### **1ï¸âƒ£ Image Encoder**
- Extracts **spatial features** from the static image.  
- Converts the input into a **latent representation**.

### **2ï¸âƒ£ Motion Module**
- Generates **motion trajectories** between frames.  
- Ensures **smooth transitions** for temporal consistency.

### **3ï¸âƒ£ Frame Generation Pipeline**
- Uses a **denoising process** to refine intermediate frames.  
- **Reconstructs pixel-level video frames** while ensuring fidelity.  

### **4ï¸âƒ£ GPU vs CPU Optimization**
- **Colab (GPU)**: Uses **CUDA acceleration** for fast generation.  
- **OpenVINO (CPU)**: Uses **model quantization & operation fusion** for efficiency.  

---

## **ğŸ“Š Experiments & Results**
This study compares **Colab (GPU)** and **OpenVINO (CPU)** in terms of **performance and video quality**.

### ğŸ“Œ **Quantitative Metrics**
| **Metric**                     | **Colab (GPU-Based)** | **OpenVINO (CPU-Based)** |
|--------------------------------|----------------------|----------------------|
| **Temporal Consistency (MSE)** | **36.90 (Lower is better)** | **55.33** |
| **Sharpness (Laplacian Variance)** | **130.91** | **605.91** |
| **Brightness (Mean Pixel Intensity)** | **124.69** | **120** |

### ğŸ“Œ **Qualitative Results**
### **1ï¸âƒ£ Colab Generated Input and Onput**
<p align="center">
  <span style="float: left;"><b>Image Input = </b></span>
  <span style="float: right;"><b>Video Output</b></span>
  <br><br>
  <img src="asset/input.png" width="400"/>
  <img src="asset/1-videoCOLAB.gif" width="400"/>
</p>

### **2ï¸âƒ£ OpenVIVO Generated Input and Output**
<p align="center">
  <span style="float: left;"><b>Image Input = </b></span>
  <span style="float: right;"><b>Video Output</b></span>
  <br><br>
  <img src="asset/input.png" width="400"/>
  <img src="asset/1-VideoOpenVIno.gif" width="400"/>
</p>

âœ… **Colab-generated videos** have **better temporal smoothness** due to GPU acceleration. 

<p align="center">
  <img src="asset/Colab_Output.png" width="700px">
</p>

âœ… **OpenVINO videos** are **resource-efficient**, making them suitable for **low-power devices**.  

<p align="center">
  <img src="asset/VINO_Output.png" width="700px">
</p>

---

## ğŸ“¥ **Installation & Usage**  

### **ğŸ”§ Setup Instructions**
To run the model, follow these steps:

### 1ï¸âƒ£ **Clone the Repository**
```bash
git clone https://github.com/JamunaSMurthy/Unsupervised-Video-Generation.git
```
2ï¸âƒ£ Navigate to the Project Directory
cd Unsupervised-Video-Generation
3ï¸âƒ£ Install the Required Dependencies
pip install -r requirements.txt
4ï¸âƒ£ Run the Video Generation Pipeline

```bash
python generate_video.py --input image.jpg --output video.mp4
```
Arguments:

--input : Path to static image.
--output : Path to generated video.
âš™ï¸ Implementation Details

- ğŸ“Œ Colab Implementation (GPU)
Uses PyTorch for stable video diffusion.
Optimized using batch processing & CUDA acceleration.
- ğŸ“Œ OpenVINO Implementation (CPU)
Uses Intel OpenVINO Runtime for inference.
Quantization & operation fusion reduce memory usage.
- ğŸ“Œ Key Libraries Used:

```bash
torch==2.0.1
diffusers==0.24.0
transformers==4.35.2
opencv-python==4.8.0
openvino==2023.1.0
```
# ğŸ”¬ Ablation Studies

We tested the impact of various optimizations on performance:

- âœ… Effect of Quantization (OpenVINO)

Without quantization: Sharper videos but slower inference.
With quantization: Faster inference with minor quality trade-offs.

- âœ… Temporal Layer Impact

Without temporal layers: Higher MSE & lower coherence.
With temporal layers: Improved smoothness & consistency.

- âœ… Noise Schedule Adjustments

Tuned schedules improved PSNR & reduced artifacts.

---
## ğŸ”® Future Enhancements

ğŸš€ Planned Improvements:

- âœ”ï¸ Real-time video generation with adaptive frame rates.
- âœ”ï¸ Hybrid GPU-CPU deployment for scalable solutions.
- âœ”ï¸ Enhancing model robustness on diverse datasets.

## ğŸ“œ Citation & References

If you use this work, please cite this repository:
```bash
@misc{JamunaSMurthy2025,
  author = {Jamuna S Murthy},
  title = {Unsupervised Video Generation from Static Images},
  year = {2025},
  howpublished = {\url{https://github.com/JamunaSMurthy/Unsupervised-Video-Generation/}},
  note = {GitHub repository}
}
```
## ğŸ“– Related Works:
Stable Video Diffusion Model â€“ HuggingFace
OpenVINO Model Optimization â€“ OpenVINO Repo
MoCoGAN: Motion and Content for Video Generation â€“ CVPR Paper

---

## ğŸ‘¨â€ğŸ’» Contributors

@JamunaSMurthy
- ğŸš€ Feel free to contribute to this repository by submitting issues or pull requests!

â­ Support & Feedback

- If you find this project useful, please â­ star this repository and share your feedback!


